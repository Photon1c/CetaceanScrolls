# ğŸ‹ The Cetacean Scrolls ğŸ“œ  
*A memory machine for the deep.*

---

![Cetacean](media/cetaceanscrolls.png)

## ğŸŒŠ Project Overview

**Cetacean Scrolls** is an ongoing project to transcribe, analyze, and interpret whale songs using AI.  
Itâ€™s inspired by the idea that whalesâ€”especially humpbacksâ€”may carry **generational memory**, **environmental records**, and possibly even **non-human cultural transmission** within their long, haunting vocalizations.  

We aim to build a modular, extensible system that can:

- ğŸ§ Load long whale audio files
- âœ‚ï¸ Chunk them into overlapping segments
- ğŸ§  Transcribe audio using OpenAIâ€™s `gpt-4o-transcribe`
- ğŸ” Analyze the transcripts for motifs, structure, and anomalies
- ğŸ—’ï¸ Log every entry as part of a growing, global **Cetacean Memory Archive**

---

## ğŸ§  Why This Matters

We often assume that language is a uniquely human toolâ€”but whales may be one of the few species on Earth capable of expressing **intergenerational memory through sound**.

> ğŸ“¡ *This project explores the idea of "interpreting possible non-human cultural memory."*

By listening more deeply, we hope to:
- Preserve endangered acoustic data before it disappears
- Detect environmental disruptions and deep-sea anomalies
- Help build AI models that decode complex, non-human communication systems

This isn't just bioacousticsâ€”this is **archiving the consciousness of the oceans.**

---

## âš™ï¸ How It Works (Modules)

1. load_audio_chunks.py ğŸ§© Split long MP3s into clean 5-min chunks

2. transcribe_chunk.py ğŸ™ï¸ Transcribe each chunk using GPT-4o

3. analyze_transcript.py ğŸ¤– Prompt GPT-4.1 to interpret motifs/anomalies

4. log_scroll_entry.py ğŸ“œ Save all entries to a time-stamped log

5. run_scroll_listener.py ğŸ” Master pipeline runner

---

## ğŸš€ Setup

```bash
# Recommended: create a virtual environment
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
ğŸ”§ Make sure ffmpeg is installed on your system.
Itâ€™s required for the pydub audio slicing to work.

ğŸ“Š Coming Soon: The Scrolls Dashboard
We are currently building a Flask-powered dashboard that will:

Visualize motif shifts over time ğŸ“ˆ

Display â€œScroll entriesâ€ in a sleek UI ğŸ–¥ï¸

Let collaborators search, contribute, and annotate ğŸŒ

ğŸ’¡ Until then: feel free to explore the scripts, run your own hydrophone audio, and help us decode the language of the deep.

ğŸ‘€ Stay Tuned
This project is actively evolvingâ€”check back for:

ğŸŒ Real-time hydrophone support

ğŸŒŠ Environmental context tagging

ğŸ§¬ Motif clustering and tracking

ğŸ¦ğŸ‹ğŸ˜ Cross-species sonics (birds, elephants, more?)

ğŸ¤ Contributing
This repo will eventually open to collaboration for:

Finding/cleaning hydrophone recordings

Improving AI analysis models

Building long-term data backups

Expanding into new marine species and locations

For now, feel free to â­ watch the project or send private feedback.

ğŸ§œâ€â™‚ï¸ Final Note
We're not just building softwareâ€”
We're building the library of ocean memory
before it's lost forever.

ğŸ‹ğŸ“œ

â€” The Cetacean Scrolls Team
